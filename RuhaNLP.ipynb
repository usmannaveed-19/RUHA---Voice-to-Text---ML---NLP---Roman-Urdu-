{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39508d48",
   "metadata": {},
   "source": [
    "### ============================================================================\n",
    "### Name        : .cpp\n",
    "### Author      : Muhammad Usman Naveed\n",
    "### Version     : Final - Release\n",
    "### Copyright   : (c) Reserved\n",
    "### Description : Voice Detection Model\n",
    "### ============================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09ac6d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pydub\n",
    "# !pip install librosa\n",
    "# !pip install soundfile\n",
    "# !pip install ffmpeg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7e4f5a",
   "metadata": {},
   "source": [
    "### Importing necessary libraraies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ce5868c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from zipfile import ZipFile\n",
    "import os.path\n",
    "import shutil \n",
    "import pydub\n",
    "from os import path\n",
    "from pydub import AudioSegment\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import csv\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990cfa03",
   "metadata": {},
   "source": [
    "### GETTING THE PATH OF THE CURRENT WORKING DIRECTORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bc0dd87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path:  C:\\Users\\Usman Naveed\\Desktop\\PAI Project\n"
     ]
    }
   ],
   "source": [
    "# GETTING THE PATH OF THE CURRENT WORKING DIRECTORY\n",
    "path = os.getcwd()\n",
    "print(\"Path: \", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c185d1aa",
   "metadata": {},
   "source": [
    "### EXTRACTING THE MAIN ZIP FOLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25fb0f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path:  C:\\Users\\Usman Naveed\\Desktop\\PAI Project\n",
      "Extracting the main Zip Folder......\n",
      "Done!\n",
      "Main Folder Found\n",
      "ROOT DIRECTORY:  C:\\Users\\Usman Naveed\\Desktop\\PAI Project\\PAI_VolunteerTask\n"
     ]
    }
   ],
   "source": [
    "# EXTRACTING THE MAIN ZIP FOLDER\n",
    "os.chdir(path)\n",
    "print(\"Path: \", os.getcwd())\n",
    "file_name = \"PAI_VolunteerTask.zip\"\n",
    "\n",
    "with ZipFile(file_name, 'r') as zip:\n",
    "#     zip.printdir()\n",
    "    print('Extracting the main Zip Folder......')\n",
    "    name_list = []\n",
    "    zip.extractall()\n",
    "    name_list = zip.namelist()\n",
    "    print('Done!')\n",
    "    \n",
    "# FIND THE EXTRACTED FOLDER AND MAKE IT THE ROOT PATH \n",
    "rootdir = \"\"\n",
    "mainFolder = \"PAI_VolunteerTask\"\n",
    "for root, subdirs, files in os.walk(os.getcwd()):\n",
    "    for d in subdirs:\n",
    "        if d == mainFolder:\n",
    "            print(\"Main Folder Found\")\n",
    "            os.chdir(path + \"\\\\\" + mainFolder)\n",
    "            rootdir = os.getcwd()\n",
    "            break\n",
    "            \n",
    "print(\"ROOT DIRECTORY: \", rootdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aaccc6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4ee3ab9d",
   "metadata": {},
   "source": [
    "### MFCC FEATURES LIST "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5637488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path:  C:\\Users\\Usman Naveed\\Desktop\\PAI Project\\PAI_VolunteerTask\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usman Naveed\\anaconda3\\lib\\site-packages\\librosa\\core\\audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "C:\\Users\\Usman Naveed\\anaconda3\\lib\\site-packages\\librosa\\core\\audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n"
     ]
    }
   ],
   "source": [
    "# MFCC FEATURES LIST \n",
    "\n",
    "os.chdir(rootdir)\n",
    "print(\"Path: \", os.getcwd())\n",
    "\n",
    "classes = os.listdir(os.getcwd())\n",
    "\n",
    "MFCC = []\n",
    "FileNames = []\n",
    "Label = []\n",
    "n = -1\n",
    "\n",
    "for x in classes:\n",
    "    n += 1\n",
    "    os.chdir(rootdir + \"\\\\\" + x)\n",
    "    for audio_path in os.listdir(os.getcwd()):\n",
    "        X , SR = librosa.load(audio_path)\n",
    "        MFCC_Features = librosa.feature.mfcc(y = X, sr = SR)\n",
    "        MFCC.append(MFCC_Features)\n",
    "        Label.append(n)\n",
    "        FileNames.append(audio_path)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22138ff7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5617f4c6",
   "metadata": {},
   "source": [
    "### MAKING A MFCC LIST TO CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28d6aa61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location of MFCC.csv:  C:\\Users\\Usman Naveed\\Desktop\\PAI Project\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usman Naveed\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:309: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  values = np.array([convert(v) for v in values])\n"
     ]
    }
   ],
   "source": [
    "# MAKING A MFCC LIST TO DATAFRAME\n",
    "os.chdir(path)\n",
    "print(\"Location of MFCC.csv: \", os.getcwd())\n",
    "df_mfcc = pd.DataFrame(MFCC)\n",
    "df_mfcc.to_csv('MFCC.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998263d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd1962ab",
   "metadata": {},
   "source": [
    "### WE CAN READ DATA FROM CSV TO HAVE MFCC FEATURES LIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98779a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# READING A DATA FROM CSV TO HAVE MFCC FEATURES LIST\n",
    "file = open(\"MFCC.csv\", \"r\")\n",
    "csv_reader = csv.reader(file)\n",
    "\n",
    "MFCC_list = []\n",
    "for row in csv_reader:\n",
    "    MFCC_list.append(row)\n",
    "\n",
    "print(MFCC_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ea2a04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c5313577",
   "metadata": {},
   "source": [
    "### TAKING TRANSPOSE AND MEAN OF THE MFCC FEATURES LIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d806d468",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TAKING TRANSPOSE AND MEAN OF THE MFCC FEATURES LIST\n",
    "\n",
    "MFCC_MEAN = []\n",
    "for i in range(0,len(MFCC)):\n",
    "    MFCC_MEAN.append(np.mean(MFCC[i].T, axis=0))\n",
    "# MFCC_MEAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0557e213",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "47b04a18",
   "metadata": {},
   "source": [
    "### FLATTEN AND PADDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cbe3bfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Labels</th>\n",
       "      <th>MFCC Features</th>\n",
       "      <th>MFCC Mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[-717.5712, -717.5712, -717.0941, -717.1781, -...</td>\n",
       "      <td>[-491.33414, 116.10739, 5.0026007, 19.08632, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[-464.71918, -435.68018, -427.7529, -427.6081,...</td>\n",
       "      <td>[-357.92642, 71.06488, 22.784355, 15.4980135, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[-669.71497, -669.71497, -653.0248, -630.79724...</td>\n",
       "      <td>[-393.05588, 122.87493, 52.46836, -3.8200877, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[-559.966, -559.966, -504.3064, -353.51645, -3...</td>\n",
       "      <td>[-317.92526, 92.107704, 17.818577, 25.37494, 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>[-479.9994, -451.33322, -440.08194, -439.05313...</td>\n",
       "      <td>[-379.72556, 60.72446, 38.965378, -8.665557, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6465</th>\n",
       "      <td>3</td>\n",
       "      <td>[-529.7096, -527.4151, -529.144, -528.17236, -...</td>\n",
       "      <td>[-394.28625, 93.22102, 14.825175, 21.706749, 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6466</th>\n",
       "      <td>3</td>\n",
       "      <td>[-464.78415, -460.64105, -453.20917, -464.6736...</td>\n",
       "      <td>[-368.06393, 108.18454, 24.29488, 28.617796, 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6467</th>\n",
       "      <td>3</td>\n",
       "      <td>[-464.78415, -460.64105, -453.20917, -464.6736...</td>\n",
       "      <td>[-368.06393, 108.18454, 24.29488, 28.617796, 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6468</th>\n",
       "      <td>3</td>\n",
       "      <td>[-527.009, -527.4413, -526.5463, -523.66284, -...</td>\n",
       "      <td>[-368.76834, 112.900406, 17.835201, 14.849443,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6469</th>\n",
       "      <td>3</td>\n",
       "      <td>[-510.37036, -509.6617, -512.70636, -520.0435,...</td>\n",
       "      <td>[-424.49582, 92.416664, 23.65278, 15.567381, 9...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6470 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Labels                                      MFCC Features  \\\n",
       "0          0  [-717.5712, -717.5712, -717.0941, -717.1781, -...   \n",
       "1          0  [-464.71918, -435.68018, -427.7529, -427.6081,...   \n",
       "2          0  [-669.71497, -669.71497, -653.0248, -630.79724...   \n",
       "3          0  [-559.966, -559.966, -504.3064, -353.51645, -3...   \n",
       "4          0  [-479.9994, -451.33322, -440.08194, -439.05313...   \n",
       "...      ...                                                ...   \n",
       "6465       3  [-529.7096, -527.4151, -529.144, -528.17236, -...   \n",
       "6466       3  [-464.78415, -460.64105, -453.20917, -464.6736...   \n",
       "6467       3  [-464.78415, -460.64105, -453.20917, -464.6736...   \n",
       "6468       3  [-527.009, -527.4413, -526.5463, -523.66284, -...   \n",
       "6469       3  [-510.37036, -509.6617, -512.70636, -520.0435,...   \n",
       "\n",
       "                                              MFCC Mean  \n",
       "0     [-491.33414, 116.10739, 5.0026007, 19.08632, -...  \n",
       "1     [-357.92642, 71.06488, 22.784355, 15.4980135, ...  \n",
       "2     [-393.05588, 122.87493, 52.46836, -3.8200877, ...  \n",
       "3     [-317.92526, 92.107704, 17.818577, 25.37494, 9...  \n",
       "4     [-379.72556, 60.72446, 38.965378, -8.665557, 0...  \n",
       "...                                                 ...  \n",
       "6465  [-394.28625, 93.22102, 14.825175, 21.706749, 6...  \n",
       "6466  [-368.06393, 108.18454, 24.29488, 28.617796, 9...  \n",
       "6467  [-368.06393, 108.18454, 24.29488, 28.617796, 9...  \n",
       "6468  [-368.76834, 112.900406, 17.835201, 14.849443,...  \n",
       "6469  [-424.49582, 92.416664, 23.65278, 15.567381, 9...  \n",
       "\n",
       "[6470 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FLATTEN AND PADDING\n",
    "\n",
    "FlattenValues = []\n",
    "FlattenMean = []\n",
    "maxVal=0\n",
    "for i in range(0,len(MFCC)):\n",
    "    FlattenValues.append(np.array(MFCC[i]).flatten())\n",
    "    FlattenMean.append(np.array(MFCC_MEAN[i]).flatten())\n",
    "    if FlattenValues[i].shape[0]>maxVal:\n",
    "        maxVal=FlattenValues[i].shape[0]\n",
    "\n",
    "PaddedValues = []\n",
    "PaddedMean = []\n",
    "for i in range(0,len(FlattenValues)):\n",
    "    np.pad(FlattenValues[i], (0, maxVal-len(FlattenValues[i])))\n",
    "    PaddedValues.append(np.pad(FlattenValues[i], (0, maxVal-len(FlattenValues[i]))))\n",
    "    PaddedMean.append(np.pad(FlattenMean[i], (0, maxVal-len(FlattenMean[i]))))\n",
    "    \n",
    "# print(PaddedValues)\n",
    "    \n",
    "PaddedDF = pd.DataFrame({\"Labels\":Label, \"MFCC Features\":PaddedValues, \"MFCC Mean\":PaddedMean})\n",
    "print(PaddedDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364bfef5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82c34614",
   "metadata": {},
   "source": [
    "### SKLEARN IMPORT LIBRARIES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad102453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SKLEARN IMPORT LIBRARIES \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f44f779",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe019aa1",
   "metadata": {},
   "source": [
    "### TRAIN_TEST_SPLIT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d920cca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train =  (5823,)\n",
      "Shape of y_train =  (5823,)\n",
      "Shape of X_test =  (647,)\n",
      "Shape of y_test =  (647,)\n"
     ]
    }
   ],
   "source": [
    "# TRAIN_TEST_SPLIT()\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(PaddedDF[\"MFCC Mean\"], PaddedDF[\"Labels\"], test_size = 0.1)\n",
    "print('Shape of X_train = ', X_train.shape)\n",
    "print('Shape of y_train = ', y_train.shape)\n",
    "print('Shape of X_test = ', X_test.shape)\n",
    "print('Shape of y_test = ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2a050f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c2ff458",
   "metadata": {},
   "source": [
    "### CONVERTING X_train and X_test into LIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ebf7b93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONVERTING X_train and X_test into LIST\n",
    "X_train = list(X_train)\n",
    "X_test = list(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f009d1a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a4fbd2f",
   "metadata": {},
   "source": [
    "### DECISION TREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "094ac27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY :  63.214837712519326\n",
      "F1 SCORE :  63.214837712519326\n",
      "RECALL SCORE 63.214837712519326\n",
      "PRECISION SCORE 63.214837712519326\n",
      "CONFUSION MATRIX [[ 18   8   0  17]\n",
      " [ 20 270  16  51]\n",
      " [  5  20  16  13]\n",
      " [ 11  61  16 105]]\n"
     ]
    }
   ],
   "source": [
    "# DECISION TREE\n",
    "from sklearn.tree import DecisionTreeClassifier  \n",
    "\n",
    "dt_model = DecisionTreeClassifier(criterion='entropy', random_state=0)  \n",
    "dt_model = dt_model.fit(X_train, y_train)\n",
    "\n",
    "# PREDICTION \n",
    "pred = dt_model.predict(X_test)\n",
    "print (\"ACCURACY : \", accuracy_score(y_test,pred)*100)  \n",
    "print(\"F1 SCORE : \", f1_score(y_test, pred, average = 'micro')*100)\n",
    "print(\"RECALL SCORE\", recall_score(y_test, pred, average = 'micro')*100)\n",
    "print(\"PRECISION SCORE\", precision_score(y_test, pred, average = 'micro')*100)\n",
    "print(\"CONFUSION MATRIX\", confusion_matrix(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b64e4af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e98fd37b",
   "metadata": {},
   "source": [
    "### K-NEAREST NEIGHBORS (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "046b1e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY :  77.27975270479135\n",
      "F1 SCORE :  77.27975270479135\n",
      "RECALL SCORE 77.27975270479135\n",
      "PRECISION SCORE 77.27975270479135\n",
      "CONFUSION MATRIX [[ 27   7   2   7]\n",
      " [  6 320   3  28]\n",
      " [  2  15  24  13]\n",
      " [ 13  43   8 129]]\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_model = KNeighborsClassifier(n_neighbors=1)\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# PREDICTION\n",
    "pred = knn_model.predict(X_test)\n",
    "print (\"ACCURACY : \", accuracy_score(y_test,pred)*100)  \n",
    "print(\"F1 SCORE : \", f1_score(y_test, pred, average = 'micro')*100)\n",
    "print(\"RECALL SCORE\", recall_score(y_test, pred, average = 'micro')*100)\n",
    "print(\"PRECISION SCORE\", precision_score(y_test, pred, average = 'micro')*100)\n",
    "print(\"CONFUSION MATRIX\", confusion_matrix(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da3664d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41c92725",
   "metadata": {},
   "source": [
    "### LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d0dda1d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY :  59.04173106646059\n",
      "F1 SCORE :  59.04173106646059\n",
      "RECALL SCORE 59.04173106646059\n",
      "PRECISION SCORE 59.04173106646059\n",
      "CONFUSION MATRIX [[  1  28   0  14]\n",
      " [  1 326   0  30]\n",
      " [  0  46   0   8]\n",
      " [  0 138   0  55]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usman Naveed\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# LOGISTIC REGRESSION\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_model = LogisticRegression(random_state=6000)\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# PREDICTION\n",
    "pred = lr_model.predict(X_test)\n",
    "print (\"ACCURACY : \", accuracy_score(y_test,pred)*100)  \n",
    "print(\"F1 SCORE : \", f1_score(y_test, pred, average = 'micro')*100)\n",
    "print(\"RECALL SCORE\", recall_score(y_test, pred, average = 'micro')*100)\n",
    "print(\"PRECISION SCORE\", precision_score(y_test, pred, average = 'micro')*100)\n",
    "print(\"CONFUSION MATRIX\", confusion_matrix(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5af9116",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "498ef227",
   "metadata": {},
   "source": [
    "### RANDOM FOREST CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d0baf69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY :  73.41576506955178\n",
      "F1 SCORE :  73.41576506955178\n",
      "RECALL SCORE 73.41576506955178\n",
      "PRECISION SCORE 73.41576506955178\n",
      "CONFUSION MATRIX [[  7  23   0  13]\n",
      " [  0 351   0   6]\n",
      " [  0  36   2  16]\n",
      " [  0  78   0 115]]\n"
     ]
    }
   ],
   "source": [
    "# RANDOM FOREST CLASSIFIER\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc_model = RandomForestClassifier(max_depth=50, random_state=0)\n",
    "rfc_model.fit(X_train, y_train)\n",
    "\n",
    "# PREDICTION\n",
    "pred = rfc_model.predict(X_test)\n",
    "print (\"ACCURACY : \", accuracy_score(y_test,pred)*100)  \n",
    "print(\"F1 SCORE : \", f1_score(y_test, pred, average = 'micro')*100)\n",
    "print(\"RECALL SCORE\", recall_score(y_test, pred, average = 'micro')*100)\n",
    "print(\"PRECISION SCORE\", precision_score(y_test, pred, average = 'micro')*100)\n",
    "print(\"CONFUSION MATRIX\", confusion_matrix(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b60f46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dbeb75e7",
   "metadata": {},
   "source": [
    "### GRADIENT BOOSTING CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31336b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY :  66.61514683153014\n",
      "F1 SCORE :  66.61514683153014\n",
      "RECALL SCORE 66.61514683153014\n",
      "PRECISION SCORE 66.61514683153014\n",
      "CONFUSION MATRIX [[  8  21   0  14]\n",
      " [  2 333   2  20]\n",
      " [  0  42   2  10]\n",
      " [  2 101   2  88]]\n"
     ]
    }
   ],
   "source": [
    "# GRADIENT BOOSTING CLASSIFIER\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb_model = GradientBoostingClassifier()\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# PREDICTION\n",
    "pred = gb_model.predict(X_test)\n",
    "print (\"ACCURACY : \", accuracy_score(y_test,pred)*100)  \n",
    "print(\"F1 SCORE : \", f1_score(y_test, pred, average = 'micro')*100)\n",
    "print(\"RECALL SCORE\", recall_score(y_test, pred, average = 'micro')*100)\n",
    "print(\"PRECISION SCORE\", precision_score(y_test, pred, average = 'micro')*100)\n",
    "print(\"CONFUSION MATRIX\", confusion_matrix(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4373b97a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a9d07e8",
   "metadata": {},
   "source": [
    "### SUPPORT VECTOR MACHINES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5db3042d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY :  55.17774343122102\n",
      "F1 SCORE :  55.17774343122102\n",
      "RECALL SCORE 55.17774343122102\n",
      "PRECISION SCORE 55.17774343122102\n",
      "CONFUSION MATRIX [[  0  43   0   0]\n",
      " [  0 357   0   0]\n",
      " [  0  54   0   0]\n",
      " [  0 193   0   0]]\n"
     ]
    }
   ],
   "source": [
    "# SUPPORT VECTOR MACHINES\n",
    "from sklearn import svm\n",
    "\n",
    "svm_model = svm.SVC()\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# PREDICTION\n",
    "pred = svm_model.predict(X_test)\n",
    "print (\"ACCURACY : \", accuracy_score(y_test,pred)*100)  \n",
    "print(\"F1 SCORE : \", f1_score(y_test, pred, average = 'micro')*100)\n",
    "print(\"RECALL SCORE\", recall_score(y_test, pred, average = 'micro')*100)\n",
    "print(\"PRECISION SCORE\", precision_score(y_test, pred, average = 'micro')*100)\n",
    "print(\"CONFUSION MATRIX\", confusion_matrix(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7c03a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "05bdb9a6",
   "metadata": {},
   "source": [
    "### GENERATING PICKLE FILES FOR ALL MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "398b6346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path:  C:\\Users\\Usman Naveed\\Desktop\\PAI Project\n",
      "pkl Files Created\n"
     ]
    }
   ],
   "source": [
    "# GENERATING PICKLE FILES FOR ALL MODELS\n",
    "os.chdir(path)\n",
    "print(\"Path: \", os.getcwd())\n",
    "\n",
    "\n",
    "dt_model_file = \"Decision Tree Model.pkl\"\n",
    "pickle.dump(dt_model, open(dt_model_file,'wb'))\n",
    "\n",
    "knn_model_file = \"K-Nearest Neighbor.pkl\"\n",
    "pickle.dump(knn_model, open(knn_model_file,'wb'))\n",
    "\n",
    "rfc_model_file = \"Random Forest Classifier.pkl\"\n",
    "pickle.dump(rfc_model, open(rfc_model_file,'wb'))\n",
    "\n",
    "svm_model_file = \"Support Vector Machine.pkl\"\n",
    "pickle.dump(svm_model, open(svm_model_file,'wb'))\n",
    "\n",
    "gb_model_file = \"Gradient Boosting.pkl\"\n",
    "pickle.dump(gb_model, open(gb_model_file,'wb'))\n",
    "\n",
    "lr_model_file = \"Linear Regression.pkl\"\n",
    "pickle.dump(lr_model, open(lr_model_file,'wb'))\n",
    "\n",
    "print(\"pkl Files Created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed455d80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a5943e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path:  C:\\Users\\Usman Naveed\\Downloads\n",
      "\n",
      "PREDICTIONS:\n",
      "\n",
      "Decision Tree:  [1]\n",
      "Bulb-Light\n",
      "\n",
      "K-Nearest Neighbor:  [3]\n",
      "T.V\n",
      "\n",
      "Random Forest Classfier:  [1]\n",
      "Bulb-Light\n",
      "\n",
      "Support Vector Machines:  [1]\n",
      "Bulb-Light\n",
      "\n",
      "Gradient Boosting:  [1]\n",
      "Bulb-Light\n",
      "\n",
      "Linear Regression:  [3]\n",
      "T.V\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# PREDICTION FOR A SINGLE DOWNLOADED FILE\n",
    "\n",
    "# downloadFolderPath = \"C:\\\\Users\\\\Usman Naveed\\\\Downloads\"\n",
    "# os.chdir(downloadFolderPath)\n",
    "# print(\"Path: \", os.getcwd())\n",
    "# fileName = \"recorded.wav\"\n",
    "\n",
    "# mfccList = []\n",
    "# X , SR = librosa.load(fileName)\n",
    "# mfcc1 = librosa.feature.mfcc(y = X, sr = SR)\n",
    "# mfcc1 = np.mean(mfcc1.T, axis=0)\n",
    "# # mfcc1 = np.array(mfcc1.flatten())\n",
    "# # mfcc1 = np.pad(mfcc1, (0, maxVal - len(mfcc1)))\n",
    "# mfccList.append(mfcc1) \n",
    "# # print(mfcc1)\n",
    "\n",
    "# def prediction_folder(p):\n",
    "#     if p == 0:\n",
    "#         print(\"A.C\\n\")\n",
    "#     if p == 1:\n",
    "#         print(\"Bulb-Light\\n\")\n",
    "#     if p == 2:\n",
    "#         print(\"Gaana-Song\\n\")\n",
    "#     if p == 3:\n",
    "#         print(\"T.V\\n\")\n",
    "\n",
    "# print(\"\\nPREDICTIONS:\\n\")\n",
    "# pred = dt_model.predict(mfccList)\n",
    "# print(\"Decision Tree: \", pred)\n",
    "# prediction_folder(pred)\n",
    "\n",
    "# pred = knn_model.predict(mfccList)\n",
    "# print(\"K-Nearest Neighbor: \", pred)\n",
    "# prediction_folder(pred)\n",
    "\n",
    "# pred = rfc_model.predict(mfccList)\n",
    "# print(\"Random Forest Classfier: \", pred)\n",
    "# prediction_folder(pred)\n",
    "\n",
    "# pred = svm_model.predict(mfccList)\n",
    "# print(\"Support Vector Machines: \", pred)\n",
    "# prediction_folder(pred)\n",
    "\n",
    "# pred = gb_model.predict(mfccList)\n",
    "# print(\"Gradient Boosting: \", pred)\n",
    "# prediction_folder(pred)\n",
    "\n",
    "# pred = lr_model.predict(mfccList)\n",
    "# print(\"Linear Regression: \", pred)\n",
    "# prediction_folder(pred)\n",
    "\n",
    "# # FOR DELETING THE DOWNLOADED FILE\n",
    "# os.remove(fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f2435e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f05e9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
